2022-05-22 00:17:34,817 | root |  DEBUG: Current configuration: {'training': False, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('u_layer', ModuleList(
  (0): ModuleList(
    (0): Linear(in_features=4, out_features=100, bias=True)
    (1): Linear(in_features=100, out_features=100, bias=True)
    (2): Linear(in_features=100, out_features=100, bias=True)
    (3): Linear(in_features=100, out_features=3, bias=True)
  )
)), ('u_bn_layer', ModuleList(
  (0): ModuleList(
    (0): BatchNorm1d(4, eps=0.5, momentum=0.1, affine=False, track_running_stats=True)
    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)), ('p_layer', ModuleList(
  (0): ModuleList(
    (0): Linear(in_features=3, out_features=100, bias=True)
    (1): Linear(in_features=100, out_features=100, bias=True)
    (2): Linear(in_features=100, out_features=100, bias=True)
    (3): Linear(in_features=100, out_features=1, bias=True)
  )
)), ('p_bn_layer', ModuleList(
  (0): ModuleList(
    (0): BatchNorm1d(3, eps=0.5, momentum=0.1, affine=False, track_running_stats=True)
    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)), ('loss', MSELoss()), ('activation', Tanh())]), 'problem_name': 'abc_3d', 'f_fun': <function f_example at 0x7f75b475b700>, 'phi_fun': <function phi_example at 0x7f75b475b160>, 'phi0': 0, 'conditional_probability_to_survive': <function Net.<lambda> at 0x7f75c0377550>, 'is_x_inside': <function Net.<lambda> at 0x7f75c03775e0>, 'deriv_map': array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 0, 0],
       [0, 0, 0],
       [0, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 1]]), 'n': 15, 'dim_in': 3, 'zeta_map': array([-1, -1, -1,  0,  1,  2,  0,  0,  0,  1,  1,  1,  2,  2,  2]), 'deriv_condition_deriv_map': array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1]]), 'deriv_condition_zeta_map': array([0, 1, 2]), 'dim_out': 3, 'nprime': 3, 'train_for_p': False, 'patches': 1, 'code': array([[-1, -1, -1],
       [-1, -1, -1],
       [-1, -1, -1]]), 'coordinate': array([0, 1, 2]), 'fdb_lookup': {(1, 0, 0): [fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(1, 0, 0): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})], (0, 1, 0): [fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 1, 0): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})], (0, 0, 1): [fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}), fdb(coeff=1, lamb=(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={(0, 0, 1): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})], (0, 0, 0): [fdb(coeff=1, lamb=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), l_and_k={})]}, 'fdb_runtime': 0.26873135566711426, 'mechanism_tot_len': 858, 'lr': 0.01, 'lr_milestones': [1000, 2000], 'lr_gamma': 0.1, 'weight_decay': 0, 'save_for_best_model': False, 'save_data': False, 'batch_normalization': True, 'nb_states': 100000, 'nb_states_per_batch': 1000, 'nb_path_per_state': 1000, 'x_lo': 0, 'x_hi': 6.283185307179586, 'adjusted_x_boundaries': (-0.6283185307179586, 6.911503837897545), 't_lo': 0.0, 't_hi': 0.7, 'T': 0.7, 'tau_lo': 1e-05, 'tau_hi': 10, 'nu': 0.0002, 'delta_t': 0.7, 'outlier_percentile': 1, 'outlier_multiplier': 10, 'exponential_lambda': 0.07327613483935798, 'epochs': 10000, 'antithetic': True, 'device': device(type='cuda'), 'verbose': True, 'fix_all_dim_except_first': False, 'fix_t_dim': False, 't_boundaries': tensor([0.7000, 0.0000], device='cuda:0'), 'adjusted_t_boundaries': [(tensor(0., device='cuda:0'), tensor(0.7000, device='cuda:0'))], 'working_dir': 'logs/20220522-001734-abc_3d-T0.7-nu0.0002'}
2022-05-22 01:12:47,521 | root |  INFO: Patch 0: generation of u samples take 3312.6908071041107 seconds.
2022-05-22 01:12:47,607 | root |  INFO: Patch  0: epoch    0 with loss 8.82E-05
2022-05-22 01:13:09,686 | root |  INFO: Patch  0: epoch  500 with loss 2.93E-04
2022-05-22 01:13:31,816 | root |  INFO: Patch  0: epoch 1000 with loss 9.90E-05
2022-05-22 01:13:53,971 | root |  INFO: Patch  0: epoch 1500 with loss 9.07E-05
2022-05-22 01:14:16,134 | root |  INFO: Patch  0: epoch 2000 with loss 8.13E-05
2022-05-22 01:14:38,467 | root |  INFO: Patch  0: epoch 2500 with loss 8.03E-05
2022-05-22 01:15:00,818 | root |  INFO: Patch  0: epoch 3000 with loss 7.88E-05
2022-05-22 01:15:23,183 | root |  INFO: Patch  0: epoch 3500 with loss 7.70E-05
2022-05-22 01:15:45,556 | root |  INFO: Patch  0: epoch 4000 with loss 7.47E-05
2022-05-22 01:16:07,920 | root |  INFO: Patch  0: epoch 4500 with loss 7.20E-05
2022-05-22 01:16:30,317 | root |  INFO: Patch  0: epoch 5000 with loss 6.88E-05
2022-05-22 01:16:52,696 | root |  INFO: Patch  0: epoch 5500 with loss 6.52E-05
2022-05-22 01:17:15,069 | root |  INFO: Patch  0: epoch 6000 with loss 6.11E-05
2022-05-22 01:17:37,447 | root |  INFO: Patch  0: epoch 6500 with loss 5.67E-05
2022-05-22 01:17:59,824 | root |  INFO: Patch  0: epoch 7000 with loss 5.20E-05
2022-05-22 01:18:22,200 | root |  INFO: Patch  0: epoch 7500 with loss 4.71E-05
2022-05-22 01:18:44,583 | root |  INFO: Patch  0: epoch 8000 with loss 4.23E-05
2022-05-22 01:19:06,970 | root |  INFO: Patch  0: epoch 8500 with loss 3.76E-05
2022-05-22 01:19:29,348 | root |  INFO: Patch  0: epoch 9000 with loss 3.31E-05
2022-05-22 01:19:51,721 | root |  INFO: Patch  0: epoch 9500 with loss 2.90E-05
2022-05-22 01:20:14,043 | root |  INFO: Patch  0: epoch 9999 with loss 2.55E-05
2022-05-22 01:20:14,054 | root |  INFO: Patch 0: training of u with 10000 epochs take 446.5323190689087 seconds.
2022-05-22 01:20:14,889 | root |  INFO: The error as in Lejay is calculated as follows.
2022-05-22 01:20:14,890 | root |  INFO: $\hat{e}_0(t_k)$
2022-05-22 01:20:14,995 | root |  INFO: & 1.85E-04 & 1.48E-04 & 1.47E-04 & 1.43E-04 & 1.41E-04 & 1.43E-04 & 1.47E-04 & 1.46E-04 & 1.54E-04 & 1.54E-04 & --- \\
2022-05-22 01:20:14,995 | root |  INFO: $\hat{e}_1(t_k)$
2022-05-22 01:20:14,997 | root |  INFO: & 1.77E-04 & 1.63E-04 & 1.50E-04 & 1.37E-04 & 1.26E-04 & 1.22E-04 & 1.28E-04 & 1.39E-04 & 1.52E-04 & 1.66E-04 & --- \\
2022-05-22 01:20:14,998 | root |  INFO: $\hat{e}_2(t_k)$
2022-05-22 01:20:14,999 | root |  INFO: & 1.77E-04 & 1.70E-04 & 1.60E-04 & 1.49E-04 & 1.32E-04 & 1.19E-04 & 1.18E-04 & 1.14E-04 & 1.06E-04 & 1.04E-04 & --- \\
2022-05-22 01:20:15,000 | root |  INFO: $\hat{e}(t_k)$
2022-05-22 01:20:15,002 | root |  INFO: & 2.49E-04 & 2.09E-04 & 2.06E-04 & 2.10E-04 & 2.14E-04 & 2.17E-04 & 2.12E-04 & 2.13E-04 & 2.08E-04 & 2.08E-04 & --- \\
2022-05-22 01:20:15,003 | root |  INFO: \hline
2022-05-22 01:20:15,003 | root |  INFO: 
The relative L2 error of u (erru) is calculated as follows.
2022-05-22 01:20:15,006 | root |  INFO: erru($t_k$)
2022-05-22 01:20:15,016 | root |  INFO: & 6.46E-03 & 5.85E-03 & 5.52E-03 & 5.38E-03 & 5.35E-03 & 5.38E-03 & 5.44E-03 & 5.56E-03 & 5.80E-03 & 6.22E-03 & --- \\
2022-05-22 01:20:15,917 | root |  INFO: 
The relative L2 error of gradient of u (errgu) is calculated as follows.
2022-05-22 01:20:15,943 | root |  INFO: errgu($t_k$)
2022-05-22 01:20:16,191 | root |  INFO: & 2.43E-02 & 2.39E-02 & 2.37E-02 & 2.36E-02 & 2.36E-02 & 2.36E-02 & 2.37E-02 & 2.38E-02 & 2.40E-02 & 2.43E-02 & --- \\
2022-05-22 01:20:16,191 | root |  INFO: 
The absolute divergence of u (errdivu) is calculated as follows.
2022-05-22 01:20:16,192 | root |  INFO: errdivu($t_k$)
2022-05-22 01:20:16,196 | root |  INFO: & 3.49E-02 & 3.16E-02 & 2.97E-02 & 2.88E-02 & 2.86E-02 & 2.86E-02 & 2.88E-02 & 2.93E-02 & 3.03E-02 & 3.20E-02 & --- \\
2022-05-22 01:20:16,234 | root |  INFO: 
The relative L2 error of p (errp) is calculated as follows.
2022-05-22 01:20:16,237 | root |  INFO: errp($t_k$)
2022-05-22 01:20:16,260 | root |  INFO: & --- & --- & --- & --- & --- & --- & --- & --- & --- & --- & 1.65E-02 \\
